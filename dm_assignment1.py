# -*- coding: utf-8 -*-
"""DM_Assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p-GcZjWft8v3AeFNUfwO-fTfqC8R5L7r
"""

pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/alxmamaev/flowers-recognition")

# Commented out IPython magic to ensure Python compatibility.

import warnings
warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

# data visualisation and manipulation
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
from random import shuffle  
 
#configure
# sets matplotlib to inline and displays graphs below the corressponding cell.
# %matplotlib inline  
style.use('fivethirtyeight')
sns.set(style='whitegrid',color_codes=True)

#model selection
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.preprocessing import LabelEncoder

#preprocess.
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#dl libraraies
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

# specifically for cnn
import tensorflow as tf
from tensorflow.keras.layers import Flatten,Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D

classnames=['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']

X=[]
Z=[]
IMG_SIZE=150
daisy='/content/flowers-recognition/flowers/daisy'
sunflower='/content/flowers-recognition/flowers/sunflower'
tulip='/content/flowers-recognition/flowers/tulip'
dandelion='/content/flowers-recognition/flowers/dandelion'
rose='/content/flowers-recognition/flowers/rose'

def assign_label(img,classname):
    return classname

def data_train(classname,DIR):
    for img in tqdm(os.listdir(DIR)):
        label=assign_label(img,classname)
        path = os.path.join(DIR,img)
        img = cv2.imread(path,cv2.IMREAD_COLOR)
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))
        
        X.append(np.array(img))
        Z.append(str(label))

import cv2                  
from tqdm import tqdm
import os

data_train('Daisy',daisy)
print(len(X))

data_train('sunflower',sunflower)
print(len(X))

data_train('tulip',tulip)
print(len(X))

data_train('Dandelion',dandelion)
print(len(X))

data_train('rose',rose)
print(len(X))

def show_picture(class_names, images, labels):
   
    
    index = np.random.randint(len(labels))
    plt.figure()
    plt.imshow(images[index])
    plt.xticks([])
    plt.yticks([])
    plt.grid(True)
    plt.title('Image #{} : '.format(index) + labels[index])
    plt.show()

show_picture(classnames, X, Z)

le=LabelEncoder()
Y=le.fit_transform(Z)
Y=to_categorical(Y,5)
X=np.array(X)
X=X/255

x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)

x_train.shape

np.random.seed(42)

model = Sequential()
model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))
model.add(MaxPooling2D(pool_size=(2,2)))


model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
 

model.add(Conv2D(filters =512, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Conv2D(filters = 512, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dense(5, activation = "softmax"))

batch_size=256
epochs=60

from keras.callbacks import ReduceLROnPlateau
red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)

datagen = ImageDataGenerator(
        featurewise_center=False,  
        samplewise_center=False,  
        featurewise_std_normalization=False,  
        samplewise_std_normalization=False,  
        zca_whitening=False,  
        rotation_range=10,  
        zoom_range = 0.1,  
        width_shift_range=0.2,  
        height_shift_range=0.2,  
        horizontal_flip=True,  
        vertical_flip=False)  


datagen.fit(x_train)

model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])

model.summary()

History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = (x_test,y_test),
                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)

pred=model.predict(x_test)
pred_digits=np.argmax(pred,axis=1)

test_digits = np.argmax(y_test,axis=1)

print("Accuracy : {}".format(accuracy_score(test_digits, pred_digits)*100))

from google.colab import drive
drive.mount('/content/drive/')

model.save('/content/drive/MyDrive/flowers/model/newmodel.h5')

from tensorflow import keras
newmodel = tf.keras.models.load_model('/content/drive/MyDrive/flowers/model/newmodel.h5')
newmodel.summary()

newmodel.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))

model.save('/content/drive/MyDrive/flowers/model/newmodel1.h5')

from tensorflow import keras
newmodel = tf.keras.models.load_model('/content/drive/MyDrive/flowers/model/newmodel.h5')

acc = newmodel.evaluate(x_train,  y_train, verbose=2)
# print(type(acc))
#print('accuracy',acc)
print('accuracy - {}'.format(acc[-1]*100))

"""References:
https://www.kaggle.com/code/almahmudalmamun/flower-recognition 

https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator 

https://www.tensorflow.org/tutorials/images/cnn 

https://keras.io/api/models/model_training_apis/ 

https://learnopencv.com/read-display-and-write-an-image-using-opencv/ 
"""

